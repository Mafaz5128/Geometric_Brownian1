import pandas as pd
import numpy as np
import warnings
# Ignore all warnings
warnings.filterwarnings('ignore')
df = pd.read_csv(r"C:\Users\mafaz\Downloads\HASU Historical Data.csv")
df.head()
df1 = df[["Date","Price"]]
df1["Time index"]=range(len(df1))
df1["Ln(xt)"] = np.log(df1["Price"])
df1["ln(x)t-1"] = np.log(df1["Price"].shift(1))
df1["logreturn_t"] = df1["Ln(xt)"] - df1["ln(x)t-1"]
df1=df1.dropna()
#estimating parameters
mu = df1['logreturn_t'].mean()
sigma = df1['logreturn_t'].std()
print(" est_mu: ",mu)
print(" est_sigma: ", sigma)

import seaborn as sns
from scipy.stats import norm

# Plot histogram of log returns
plt.figure(figsize=(12, 6))
sns.histplot(df1['logreturn_t'], bins=50, kde=True, stat='density') 
plt.title("Histogram of log returns")
plt.xlabel('log returns')
plt.ylabel('density')
plt.show()

#normaltiy test
import scipy.stats as stats
k2, p_value = stats.shapiro(df1['logreturn_t'])
print("Shapiro-Wilktest p-value:", p_value)
if p_value < 0.05:
    print("log returns does not come from a normally distribution.")
else:
    print("log returns comes from a normally distribution.")

#normaltiy test
import scipy.stats as stats
k2, p_value = stats.normaltest(df1['logreturn_t'])
print("Normality test p-value:", p_value,k2)
if p_value < 0.05:
    print("log returns does not come from a normally distribution.")
else:
    print("log returns comes from a normally distribution.")

#create a function to simulate sample paths
import math
def Geometric_Brownian (m,T,N,sigma,mu,w0,GB=False):
    # m- no of simulations
    # T- no of days
    # N- no of steps
    # mu- drift parameter
    # sigma - scale parameter
    # w0 - initial price value
    #time step
    dt = T/N
    #create an array to store simmulatated values
    x = np.zeros((m,N+1))
    #initial values of x
    x[:,0] = w0
    x0 = x[:,0] 
    if not GB:
        r = norm.rvs(size=x0.shape + (N,),loc = mu*dt, scale=sigma*math.sqrt(dt))
        np.cumsum(r,axis=1, out=x[:,1:])
        x[:,1:]+=w0
    else:
        r = norm.rvs(size=x0.shape + (N,),loc = mu*dt, scale=sigma*math.sqrt(dt))
        np.cumsum(r,axis=1, out=x[:,1:])
        if w0 !=0:
            x[:,1:]=w0*np.exp(x[:,1:])
        else:
            x[:,1:]=w0*np.exp(x[:,1:])
    return x


X=Geometric_Brownian(5000,20,20,sigma,mu,58.2,GB=True)
X.shape
simulated_df=pd.DataFrame(X)
simulated_df

# Plot the sample paths
plt.figure(figsize=(12, 6))
plt.plot(simulated_df.T)
plt.title("Simulated Sample Paths for the Next 20 Days")
plt.xlabel("Day")
plt.ylabel("Price")
plt.show()

#Box plot closing price of 20th day
plt.figure(figsize=(6, 6))
sns.boxplot(simulated_df.T.iloc[-1])
plt.title("Box Plot for Closing Prices on the Last Day of the Next 20-Day Period")
plt.xlabel("Closing Price")
plt.show()

lastday_value = simulations_df.T.iloc[-1]
prob = len(lastday_value[(lastday_value > 55) & (lastday_value < 60)])/len(lastday_value)
print("probability that the closing price corresponding to the last day of the next 20-day period is between 55 and 60 : ",prob)

prediction_interval = np.percentile(lastday_value, [2.5, 97.5])
print("prediction_interval of last day : ",prediction_interval)
